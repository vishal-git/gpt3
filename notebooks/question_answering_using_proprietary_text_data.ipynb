{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0796afd",
   "metadata": {},
   "source": [
    "This notebook shows how we can use proprietary text data and feed it to GPT-3 to get answers from it. In this example, the \"proprietary\" text data is the Summer 2020 Olympics data from Wikipedia. Since GPT-3 was not trained on data after 2020, it can't reliabily answer questions about events that took palce after that time period. Currently, if we ask ChatGPT who won the men's high jump medal, it will hallucinate and provide a wrong answer.\n",
    "\n",
    "We scrape data from Wikipedia about Summer 2020 Olympics and feed it to GPT-3 in a systematic way to get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1b1efb",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd6eb20",
   "metadata": {},
   "source": [
    " Collect data about Summer 2020 Olympics from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a22a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wikipedia as wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f478463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_olympic_2020_titles(titles):\n",
    "    titles = [title for title in titles if '2020' in title and 'olympi' in title.lower()]\n",
    "    return titles\n",
    "\n",
    "def get_wiki_page(title):\n",
    "    try:\n",
    "        return wiki.page(title)\n",
    "    except wiki.exceptions.DisambiguationError as e:\n",
    "        return wiki.page(e.options[0])\n",
    "    except wiki.exceptions.PageError as e:\n",
    "        return None\n",
    "    \n",
    "def recursively_find_all_pages(titles, titles_so_far=set()):\n",
    "    all_pages = []\n",
    "    \n",
    "    titles = list(set(titles) - titles_so_far)\n",
    "    titles = filter_olympic_2020_titles(titles)\n",
    "    titles_so_far.update(titles)\n",
    "    \n",
    "    for title in titles:\n",
    "        page = get_wiki_page(title)\n",
    "        if page is None:\n",
    "            continue\n",
    "        all_pages.append(page)\n",
    "        \n",
    "        new_pages = recursively_find_all_pages(page.links, titles_so_far)\n",
    "        \n",
    "        for pg in new_pages:\n",
    "            if pg.title not in [p.title for p in all_pages]:\n",
    "                all_pages.append(pg)\n",
    "        titles_so_far.update(page.links)\n",
    "        \n",
    "    return all_pages\n",
    "\n",
    "pages = recursively_find_all_pages(['2020 Summer Olympics'])\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20964961",
   "metadata": {},
   "source": [
    "_Note: This took about 20 minutes to run._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa26b7",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab7767",
   "metadata": {},
   "source": [
    "The next step is to remove sections that are unlikely to contain useful information, and ensure that each section is no longer than the token limit (for OpenAI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed17fb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Bermuda at the 2020 Summer Olympics',\n",
       " 'Equestrian',\n",
       " \"Bermuda entered one dressage rider into the Olympic competition by finishing in the top four, outside the group selection, of the individual FEI Olympic Rankings for Groups D and E (North, Central, and South America), marking the country's recurrence to the sport after an eight-year absence. The quota was later withdrawn, following an injury of Annabelle Collins' main horse Joyero and a failure to obtain minimum eligibility requirements (MER) aboard a new horse Chuppy Checker.\",\n",
       " 104)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from typing import Set\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt3\") # gpt2 was used in the code sample\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"count the number of tokens in a string\"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def reduce_long(\n",
    "    long_text: str, long_text_tokens: bool = False, max_len: int = 590\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Reduce a long text to a maximum of `max_len` tokens by potentially cutting at a sentence end\n",
    "    \"\"\"\n",
    "    if not long_text_tokens:\n",
    "        long_text_tokens = count_tokens(long_text)\n",
    "    if long_text_tokens > max_len:\n",
    "        sentences = sent_tokenize(long_text.replace(\"\\n\", \" \"))\n",
    "        ntokens = 0\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            ntokens += 1 + count_tokens(sentence)\n",
    "            if ntokens > max_len:\n",
    "                return \". \".join(sentences[:i][:-1]) + \".\"\n",
    "\n",
    "    return long_text\n",
    "\n",
    "discard_categories = ['See also', 'References', 'External links', 'Further reading', \"Footnotes\",\n",
    "    \"Bibliography\", \"Sources\", \"Citations\", \"Literature\", \"Footnotes\", \"Notes and references\",\n",
    "    \"Photo gallery\", \"Works cited\", \"Photos\", \"Gallery\", \"Notes\", \"References and sources\",\n",
    "    \"References and notes\",]\n",
    "\n",
    "\n",
    "def extract_sections(\n",
    "    wiki_text: str,\n",
    "    title: str,\n",
    "    max_len: int = 1500,\n",
    "    discard_categories: Set[str] = discard_categories,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Extract the sections of a Wikipedia page, discarding the references and other low information sections\n",
    "    \"\"\"\n",
    "    if len(wiki_text) == 0:\n",
    "        return []\n",
    "\n",
    "    # find all headings and the coresponding contents\n",
    "    headings = re.findall(\"==+ .* ==+\", wiki_text)\n",
    "    for heading in headings:\n",
    "        wiki_text = wiki_text.replace(heading, \"==+ !! ==+\")\n",
    "    contents = wiki_text.split(\"==+ !! ==+\")\n",
    "    contents = [c.strip() for c in contents]\n",
    "    assert len(headings) == len(contents) - 1\n",
    "\n",
    "    cont = contents.pop(0).strip()\n",
    "    outputs = [(title, \"Summary\", cont, count_tokens(cont)+4)]\n",
    "    \n",
    "    # discard the discard categories, accounting for a tree structure\n",
    "    max_level = 100\n",
    "    keep_group_level = max_level\n",
    "    remove_group_level = max_level\n",
    "    nheadings, ncontents = [], []\n",
    "    for heading, content in zip(headings, contents):\n",
    "        plain_heading = \" \".join(heading.split(\" \")[1:-1])\n",
    "        num_equals = len(heading.split(\" \")[0])\n",
    "        if num_equals <= keep_group_level:\n",
    "            keep_group_level = max_level\n",
    "\n",
    "        if num_equals > remove_group_level:\n",
    "            if (\n",
    "                num_equals <= keep_group_level\n",
    "            ):\n",
    "                continue\n",
    "        keep_group_level = max_level\n",
    "        if plain_heading in discard_categories:\n",
    "            remove_group_level = num_equals\n",
    "            keep_group_level = max_level\n",
    "            continue\n",
    "        nheadings.append(heading.replace(\"=\", \"\").strip())\n",
    "        ncontents.append(content)\n",
    "        remove_group_level = max_level\n",
    "\n",
    "    # count the tokens of each section\n",
    "    ncontent_ntokens = [\n",
    "        count_tokens(c)\n",
    "        + 3\n",
    "        + count_tokens(\" \".join(h.split(\" \")[1:-1]))\n",
    "        - (1 if len(c) == 0 else 0)\n",
    "        for h, c in zip(nheadings, ncontents)\n",
    "    ]\n",
    "\n",
    "    # Create a tuple of (title, section_name, content, number of tokens)\n",
    "    outputs += [(title, h, c, t) if t<max_len \n",
    "                else (title, h, reduce_long(c, max_len), count_tokens(reduce_long(c,max_len))) \n",
    "                    for h, c, t in zip(nheadings, ncontents, ncontent_ntokens)]\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "# Example page being processed into sections\n",
    "bermuda_page = get_wiki_page('Bermuda at the 2020 Summer Olympics')\n",
    "ber = extract_sections(bermuda_page.content, bermuda_page.title)\n",
    "\n",
    "# Example section\n",
    "ber[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4547063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vishal/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8343b5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Summary</td>\n",
       "      <td>The 2020 Summer Olympics (Japanese: 2020年夏季オリン...</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Host city selection</td>\n",
       "      <td>The International Olympic Committee (IOC) vote...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Impact of the COVID-19 pandemic</td>\n",
       "      <td>In January 2020, concerns were raised about th...</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Qualifying event cancellation and postponement</td>\n",
       "      <td>Concerns about the pandemic began to affect qu...</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Effect on doping tests</td>\n",
       "      <td>Mandatory doping tests were being severely res...</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                         heading  \\\n",
       "0  2020 Summer Olympics                                         Summary   \n",
       "1  2020 Summer Olympics                             Host city selection   \n",
       "2  2020 Summer Olympics                 Impact of the COVID-19 pandemic   \n",
       "3  2020 Summer Olympics  Qualifying event cancellation and postponement   \n",
       "4  2020 Summer Olympics                          Effect on doping tests   \n",
       "\n",
       "                                             content  tokens  \n",
       "0  The 2020 Summer Olympics (Japanese: 2020年夏季オリン...     730  \n",
       "1  The International Olympic Committee (IOC) vote...     126  \n",
       "2  In January 2020, concerns were raised about th...     374  \n",
       "3  Concerns about the pandemic began to affect qu...     298  \n",
       "4  Mandatory doping tests were being severely res...     163  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for page in pages:\n",
    "    res += extract_sections(page.content, page.title)\n",
    "\n",
    "df = pd.DataFrame(res, columns=[\"title\", \"heading\", \"content\", \"tokens\"])\n",
    "df = df[df.tokens > 40]\n",
    "df = df.drop_duplicates(['title','heading'])\n",
    "df = df.reset_index().drop('index',axis=1) # reset index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6746cd",
   "metadata": {},
   "source": [
    "_Note: This took about 10-15 minutes to run._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d42e8",
   "metadata": {},
   "source": [
    "Let's save this dataset for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78acff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/olympics_sections.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdfe0b5",
   "metadata": {},
   "source": [
    "# Question Answering using Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c947cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishal/code/gpt3/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "COMPLETIONS_MODEL = 'text-davinci-002' # NOTE: instead of this, use the latest, cheaper model: 'text-embedding-ada-002'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b8c2a1",
   "metadata": {},
   "source": [
    "We will need to use the OpenAI API key to call their API. I have stored the API in `/.env` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "831b19bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "975d45c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "env_path = Path('..')/'.env'\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "63c8be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc8004f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 2020 Summer Olympics men's high jump was won by Mariusz Przybylski of Poland.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Who won the 2020 Summer Olympics men's high jump?\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL)['choices'][0]['text'].strip(' \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd14fa",
   "metadata": {},
   "source": [
    "By default, GPT-3 doesn't do well on 2020 Olympics questions. It hallucinates! Note that this answer changes over time. I tried the same question on 1/26/2023 and got the following answer: \"The 2020 Summer Olympics were postponed to 2021 due to the COVID-19 pandemic. As such, the men's high jump event has not been held yet, and no winner has been determined.\" Ah, a very convincing answer, but it's wrong of course. It seems like ChatGPT doesn't know that we are in 2023!\n",
    "\n",
    "After prodding ChatGPT a little more, this is what it had to say: \"I apologize for any confusion - you are correct that the 2020 Summer Olympics were originally scheduled to take place in 2020, but were postponed to 2021 due to the COVID-19 pandemic. As of my last training data, which was in 2021, the Olympics had not yet taken place, so I was not able to provide information about the winner of the men's high jump. To my knowledge, The 2020 Summer Olympics did take place but I don't have the information about the winner of men's high jump as it is not included in my training data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d1002",
   "metadata": {},
   "source": [
    "Let's address the so-called 'hallucination issue' by being more explicit with the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e675209a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, I don't know.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
    "\n",
    "Q: Who won the 2020 Summer Olympics men's high jump?\n",
    "A:\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd38a9",
   "metadata": {},
   "source": [
    "Okay, that's better. Now let's provide some context and see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3b85424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Gianmarco Tamberi and Mutaz Essa Barshim won the 2020 Summer Olympics men's high jump.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible using the provided text, and if the answer is not contained within the text below, say \"I don't know\"\n",
    "\n",
    "Context:\n",
    "The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium.\n",
    "33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places \n",
    "to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021).\n",
    "Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following\n",
    "a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance\n",
    "where the athletes of different nations had agreed to share the same medal in the history of Olympics. \n",
    "Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a \n",
    "'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and \n",
    "Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump\n",
    "for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg\n",
    "of Sweden (1984 to 1992).\n",
    "\n",
    "Q: Who won the 2020 Summer Olympics men's high jump?\n",
    "A:\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114472cc",
   "metadata": {},
   "source": [
    "This is the correct answer. \n",
    "\n",
    "Okay, so we just confirmed that adding extra information into the prompt definately helps!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0440893",
   "metadata": {},
   "source": [
    "Let's load the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca92be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3946 rows in the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gymnastics at the 2020 Summer Olympics – Women's uneven bars</th>\n",
       "      <th>Background</th>\n",
       "      <td>This was the 19th appearance of the event, aft...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France at the 2020 Summer Olympics</th>\n",
       "      <th>Artistic</th>\n",
       "      <td>France fielded a full squad of seven artistic ...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium at the 2020 Summer Olympics</th>\n",
       "      <th>Swimming</th>\n",
       "      <td>Belgian swimmers achieved qualifying standards...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Badminton at the 2020 Summer Olympics – Qualification</th>\n",
       "      <th>Summary</th>\n",
       "      <td>There are 172 quota places available for quali...</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volleyball at the 2020 Summer Olympics – Men's South American qualification</th>\n",
       "      <th>Summary</th>\n",
       "      <td>The South American Qualification Tournament fo...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         content  \\\n",
       "title                                              heading                                                         \n",
       "Gymnastics at the 2020 Summer Olympics – Women'... Background  This was the 19th appearance of the event, aft...   \n",
       "France at the 2020 Summer Olympics                 Artistic    France fielded a full squad of seven artistic ...   \n",
       "Belgium at the 2020 Summer Olympics                Swimming    Belgian swimmers achieved qualifying standards...   \n",
       "Badminton at the 2020 Summer Olympics – Qualifi... Summary     There are 172 quota places available for quali...   \n",
       "Volleyball at the 2020 Summer Olympics – Men's ... Summary     The South American Qualification Tournament fo...   \n",
       "\n",
       "                                                               tokens  \n",
       "title                                              heading             \n",
       "Gymnastics at the 2020 Summer Olympics – Women'... Background      43  \n",
       "France at the 2020 Summer Olympics                 Artistic       171  \n",
       "Belgium at the 2020 Summer Olympics                Swimming        86  \n",
       "Badminton at the 2020 Summer Olympics – Qualifi... Summary        287  \n",
       "Volleyball at the 2020 Summer Olympics – Men's ... Summary         60  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/olympics_sections.csv')\n",
    "df = df.set_index([\"title\", \"heading\"])\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3116ac03",
   "metadata": {},
   "source": [
    "Now we can't possibly pass _all_ of this text data through the OpenAI API. Instead, we will pass each section content, one at a time, and create embedding for them first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67005617",
   "metadata": {},
   "source": [
    "### Create embedding for each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c878fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'curie'\n",
    "\n",
    "DOC_EMBEDDINGS_MODEL = f'text-search-{MODEL_NAME}-doc-001'\n",
    "QUERY_EMBEDDINGS_MODEL = f'text-search-{MODEL_NAME}-query-001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9824dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str):\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def get_doc_embedding(text: str):\n",
    "    return get_embedding(text, DOC_EMBEDDINGS_MODEL)\n",
    "\n",
    "def get_query_embedding(text: str):\n",
    "    return get_embedding(text, QUERY_EMBEDDINGS_MODEL)\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_doc_embedding(r.content.replace(\"\\n\", \" \")) for idx, r in df.iterrows()\n",
    "    }\n",
    "\n",
    "def load_embeddings(fname: str):\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9fbf4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3946, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61991882",
   "metadata": {},
   "source": [
    "_Note: The following API calls cost me money (around $12). If you don't want to spend any money for this, you'd have to try API throttling. Alternatively, you can skip the calls to the embeddings API and just directly use the saved embeddings from the `../data/olympics_embeddings_short.csv` file included in this repo. Please keep in mind that due to github's filesize restriction, I had to create a smaller version of the original dataset, and this 'short' dataset contains only the first 1,000 embeddings out of more than 3,900 in the original dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8669e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_embeddings = compute_doc_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d35b1209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2020 Summer Olympics', 'Summary') : [-0.001977740554139018, 0.0038539995439350605, 0.0010027086827903986, 0.008344566449522972, -0.010415716096758842]... (4096 entries)\n"
     ]
    }
   ],
   "source": [
    "# An example embedding:\n",
    "example_entry = list(context_embeddings.items())[0]\n",
    "print(f\"{example_entry[0]} : {example_entry[1][:5]}... ({len(example_entry[1])} entries)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70e6bfb",
   "metadata": {},
   "source": [
    "Export context embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f4f86c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles, all_headings, all_embeddings = [], [], []\n",
    "for keys, val in context_embeddings.items():\n",
    "    title, heading = keys\n",
    "    all_titles.append(title)\n",
    "    all_headings.append(heading)\n",
    "    all_embeddings.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "03ddba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3946, 3946, 3946)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_titles), len(all_headings), len(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "473359a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Summary</td>\n",
       "      <td>[-0.001977740554139018, 0.0038539995439350605,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Host city selection</td>\n",
       "      <td>[-0.005577346310019493, 0.0024105869233608246,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Impact of the COVID-19 pandemic</td>\n",
       "      <td>[-0.007205113768577576, -0.02255360037088394, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Qualifying event cancellation and postponement</td>\n",
       "      <td>[0.009390046820044518, -0.008730015717446804, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Effect on doping tests</td>\n",
       "      <td>[-0.0034491312690079212, -0.003978027962148189...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                         heading  \\\n",
       "0  2020 Summer Olympics                                         Summary   \n",
       "1  2020 Summer Olympics                             Host city selection   \n",
       "2  2020 Summer Olympics                 Impact of the COVID-19 pandemic   \n",
       "3  2020 Summer Olympics  Qualifying event cancellation and postponement   \n",
       "4  2020 Summer Olympics                          Effect on doping tests   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.001977740554139018, 0.0038539995439350605,...  \n",
       "1  [-0.005577346310019493, 0.0024105869233608246,...  \n",
       "2  [-0.007205113768577576, -0.02255360037088394, ...  \n",
       "3  [0.009390046820044518, -0.008730015717446804, ...  \n",
       "4  [-0.0034491312690079212, -0.003978027962148189...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb = pd.DataFrame(columns=['title', 'heading', 'embedding'])\n",
    "df_emb['title'] = all_titles\n",
    "df_emb['heading'] = all_headings\n",
    "df_emb['embedding'] = all_embeddings\n",
    "df_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5dd6b7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_emb.embedding.head(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4096):\n",
    "    df_emb[i] = df_emb['embedding'].apply(lambda x: x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "332642b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Summary</td>\n",
       "      <td>-0.001978</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.008345</td>\n",
       "      <td>-0.010416</td>\n",
       "      <td>0.017999</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>-0.035851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003051</td>\n",
       "      <td>-0.012076</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>-0.025684</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.003439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4098 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title  heading         0         1         2         3  \\\n",
       "0  2020 Summer Olympics  Summary -0.001978  0.003854  0.001003  0.008345   \n",
       "\n",
       "          4         5         6         7  ...      4086      4087      4088  \\\n",
       "0 -0.010416  0.017999 -0.003965 -0.035851  ... -0.003051 -0.012076 -0.000273   \n",
       "\n",
       "       4089      4090      4091      4092      4093      4094      4095  \n",
       "0  0.012122  0.004525 -0.000271 -0.025684  0.013848  0.019097  0.003439  \n",
       "\n",
       "[1 rows x 4098 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb = df_emb.drop(columns='embedding')\n",
    "df_emb.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8dd80b",
   "metadata": {},
   "source": [
    "Let's save these embeddings for future use. (If we don't save them, we would have to make those API calls again.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f566f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb.to_csv('../data/olympics_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a764b92b",
   "metadata": {},
   "source": [
    "Do a quick test to read is back again to make sure it's readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aacc0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = load_embeddings('../data/olympics_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd81caa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2020 Summer Olympics', 'Summary') : [-0.001977740554139, 0.003853999543935, 0.0010027086827903, 0.0083445664495229, -0.0104157160967588]... (4096 entries)\n"
     ]
    }
   ],
   "source": [
    "# an example embedding:\n",
    "example_entry2 = list(document_embeddings.items())[0]\n",
    "print(f\"{example_entry2[0]} : {example_entry2[1][:5]}... ({len(example_entry2[1])} entries)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ab4ac2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeddings == document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "678efd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3946, 3946)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context_embeddings), len(document_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f4efd",
   "metadata": {},
   "source": [
    "Okay, it looks good. We can read the embeddings from the CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9482b",
   "metadata": {},
   "source": [
    "### Find the relevant section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11efbc7c",
   "metadata": {},
   "source": [
    "Find the most similar document embedding to the question embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a0f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x, y):\n",
    "    \"\"\"\n",
    "    We could use cosine similarity or dot product to calculate the similarity between vectors.\n",
    "    In practice, we have found it makes little difference. \n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query, contexts):\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_query_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6775c2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4296262705737044,\n",
       "  (\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')),\n",
       " (0.4130726161040939,\n",
       "  (\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Background')),\n",
       " (0.4067050971353775,\n",
       "  (\"Athletics at the 2020 Summer Olympics – Women's high jump\", 'Summary')),\n",
       " (0.40424430924445215,\n",
       "  (\"Athletics at the 2020 Summer Olympics – Men's triple jump\", 'Summary')),\n",
       " (0.40219236123048674,\n",
       "  (\"Athletics at the 2020 Summer Olympics – Women's long jump\", 'Summary'))]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"Who won the men's high jump?\", document_embeddings)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80abd916",
   "metadata": {},
   "source": [
    "This makes senes. The we would expect these to be some of the relevant sections where we might find the answer to this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41656b4",
   "metadata": {},
   "source": [
    "### Add the relevant section to the query prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a1d40e",
   "metadata": {},
   "source": [
    "Now that we know we can find the relavant section (from our entire corpus of Summer 2020 Olympics), we can grab that section and include it in our prompt (that we send to GPT-3) along with our question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f93bb7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context separator contains 3 tokens'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SECTION_LEN = 500\n",
    "SEPARATOR = \"\\n* \"\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "separator_len = len(tokenizer.tokenize(SEPARATOR))\n",
    "\n",
    "f\"Context separator contains {separator_len} tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a635b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.        \n",
    "        document_section = df.loc[section_index]\n",
    "        \n",
    "        chosen_sections_len += document_section.tokens + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "            \n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "822f26da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 document sections:\n",
      "(\"Athletics at the 2020 Summer Olympics – Women's high jump\", 'Summary')\n",
      "(\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')\n",
      "(\"Athletics at the 2020 Summer Olympics – Men's triple jump\", 'Summary')\n",
      "===\n",
      " Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\n",
      "\n",
      "Context:\n",
      "\n",
      "* The women's high jump event at the 2020 Summer Olympics took place on 5 and 7 August 2021 at the Japan National Stadium. Even though 32 athletes qualified through the qualification system for the Games, only 31 took part in the competition. This was the 22nd appearance of the event, having appeared at every Olympics since women's athletics was introduced in 1928.\n",
      "* The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium. 33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021). Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance where the athletes of different nations had agreed to share the same medal in the history of Olympics. Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a 'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg of Sweden (1984 to 1992).\n",
      "* The men's triple jump event at the 2020 Summer Olympics took place between 3 and 5 August 2021 at the Japan National Stadium. Approximately 35 athletes were expected to compete; the exact number was dependent on how many nations use universality places to enter athletes in addition to the 32 qualifying through time or ranking (2 universality places were used in 2016). 32 athletes from 19 nations competed. Pedro Pichardo of Portugal won the gold medal, the nation's second victory in the men's triple jump (after Nelson Évora in 2008). China's Zhu Yaming took silver, while Hugues Fabrice Zango earned Burkina Faso's first Olympic medal in any event.\n",
      "\n",
      " Q: Who won the 2020 Summer Olympics men's high jump?\n",
      " A:\n"
     ]
    }
   ],
   "source": [
    "prompt = construct_prompt(\n",
    "    \"Who won the 2020 Summer Olympics men's high jump?\",\n",
    "    document_embeddings,\n",
    "    df)\n",
    "\n",
    "print(\"===\\n\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253f9df",
   "metadata": {},
   "source": [
    "This looks good. We have successfully added the relevant section to the prompt. \n",
    "\n",
    "Now we can answer a question based on the context!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "252f0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 300,\n",
    "    \"model\": COMPLETIONS_MODEL,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "04f51e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embeddings,\n",
    "    show_prompt: bool = False) -> str:\n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "                prompt=prompt,\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d40cb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 document sections:\n",
      "(\"Athletics at the 2020 Summer Olympics – Women's high jump\", 'Summary')\n",
      "(\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')\n",
      "(\"Athletics at the 2020 Summer Olympics – Men's triple jump\", 'Summary')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Gianmarco Tamberi and Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m.'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"Who won the 2020 Summer Olympics men's high jump?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4077f0e",
   "metadata": {},
   "source": [
    "YES! This is the correct answer!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
